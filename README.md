# This are my solutions for the Apache Spark EDX Courses 2016

## Course Introduction
### Notebook cs105_lab0.ipynb.This notebook covers:
- Part 1: Attach class helper library
- Part 2: Test Spark functionality
- Part 3: Test class helper library
- Part 4: Check plotting
- Part 5: Check MathJax formulas

### Notebook cs105_lab1a_spark_tutorial.ipynb. This notebook covers:
- Part 1: Basic notebook usage and Python integration
- Part 2: An introduction to using Apache Spark with the PySpark SQL API running in a notebook
- Part 3: Using DataFrames and chaining together transformations and actions
- Part 4: Python Lambda functions and User Defined Functions
- Part 5: Additional DataFrame actions
- Part 6: Additional DataFrame transformations
- Part 7: Caching DataFrames and storage options
- Part 8: Debugging Spark applications and lazy evaluation

### Notebook cs105_lab1b_word_count.ipynb. This notebook covers:
- Part 1: Creating a base DataFrame and performing operations
- Part 2: Counting with Spark SQL and DataFrames
- Part 3: Finding unique words and a mean value
- Part 4: Apply word count to a file

### Notebook cs105_lab2_apache_log.ipynb. This notebook covers webserver log file analysis:
- Part 1: Introduction and Imports
- Part 2: Exploratory Data Analysis
- Part 3: Analysis Walk-Through on the Web Server Log File
- Part 4: Analyzing Web Server Log File
- Part 5: Exploring 404 Response Codes

## Course Big Data Analysis with Apache Spark

### Notebook s110_lab1_power_plant_ml_pipeline.ipynb: Power Plant Machine Learning Pipeline Application. This notebook covers:
- Part 1: Business Understanding
- Part 2: Load Your Data
- Part 3: Explore Your Data
- Part 4: Visualize Your Data
- Part 5: Data Preparation
- Part 6: Data Modeling
- Part 7: Tuning and Evaluation

### Notebook cs110_lab2_als_prediction.ipynb: Predicting Movie Ratings. This notebook covers:
- Part 0: Preliminaries
- Part 1: Basic Recommendations
- Part 2: Collaborative Filtering
- Part 3: Predictions for Yourself

### Notebook cs110_lab3a_word_count_rdd.ipynb: Word Count Lab, building a word count application. This notebook covers:
- Part 1: Creating a base RDD and pair RDDs
- Part 2: Counting with pair RDDs
- Part 3: Finding unique words and a mean value
- Part 4: Apply word count to a file

### Notebook cs110_lab3b_text_analysis_and_entity_resolution.ipynb: Text Analysis and Entity Resolution. This notebook covers:
- ER as Text Similarity - Bags of Words
- ER as Text Similarity - Weighted Bag-of-Words using TF-IDF
- ER as Text Similarity - Cosine Similarity
- Scalable ER

## Course Distributed Machine Learning

### Notebook cs120_lab0.ipynb. This notebook covers:
- Part 1: Attach class helper library
- Part 2: Test Spark functionality
- Part 3: Test class helper library
- Part 4: Check plotting
- Part 5: Check MathJax formulas

### Notebook cs120_lab1a_math_review.ipynb: Math and Python review. This notebook covers:
- Part 1: Math review
- Part 2: NumPy
- Part 3: Additional NumPy and Spark linear algebra
- Part 4: Python lambda expressions

### Notebook cs120_lab1b_word_count_rdd.ipynb This notebook covers:
- Part 1: Creating a base DataFrame and performing operations
- Part 2: Counting with Spark SQL and DataFrames
- Part 3: Finding unique words and a mean value
- Part 4: Apply word count to a file

### Notebook cs120_lab2_linear_regression_df.ipynb: Linear Regression Lab. This notebook covers:
- Part 1: Read and parse the initial dataset
- Part 2: Create and evaluate a baseline model
- Part 3: Train (via gradient descent) and evaluate a linear regression mode
- Part 4: Train using SparkML and tune hyperparameters via grid search
- Part 5: Add interactions between features

### Notebook cs120_lab3_ctr_df.ipynb: Click-Through Rate Prediction Lab. This notebook covers:
- Part 1: Featurize categorical data using one-hot-encoding (OHE)
- Part 2: Construct an OHE dictionary
- Part 3: Parse CTR data and generate OHE features
- Part 4: CTR prediction and logloss evaluation
- Part 5: Reduce feature dimension via feature hashing

### Notebook cs120_lab4_pca.ipynb: Principal Component Analysis Lab. This notebook covers:
- Part 1: Work through the steps of PCA on a sample dataset
- Part 2: Write a PCA function and evaluate PCA on sample datasets
- Part 3: Parse, inspect, and preprocess neuroscience data then perform PCA
- Part 4: Perform feature-based aggregation followed by PCA


## Software requirements
This code requries at least Apache Spark 1.6 and some Databricks extensions. Best run the code in the Databricks cloud.
